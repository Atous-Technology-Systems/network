# ü§ñ LLM API - Gemma 3N TFLite

## üìã Vis√£o Geral

A API LLM permite interagir com o modelo **Gemma 3N TFLite** integrado ao sistema ATous Secure Network. Esta API fornece endpoints para consultas, m√©tricas, status e WebSocket para comunica√ß√£o em tempo real.

## üöÄ Endpoints Dispon√≠veis

### Base URL
```
http://127.0.0.1:8000/api/llm
```

### 1. Health Check
**GET** `/health`

Verifica o status geral do sistema.

**Resposta:**
```json
{
  "status": "healthy",
  "timestamp": "2025-08-17T22:15:00Z",
  "services": {
    "llm": "active",
    "abiss": "active",
    "nnis": "active"
  }
}
```

### 2. Status do LLM
**GET** `/api/llm/status`

Verifica o status espec√≠fico do modelo LLM.

**Resposta:**
```json
{
  "is_loaded": true,
  "model_type": "tflite",
  "model_path": "models/gemma-3n/extracted",
  "status": "ready",
  "timestamp": "2025-08-17T22:15:00Z"
}
```

### 3. M√©tricas do LLM
**GET** `/api/llm/metrics`

Obt√©m m√©tricas detalhadas do servi√ßo LLM.

**Resposta:**
```json
{
  "total_queries": 15,
  "successful_responses": 15,
  "average_response_time": 0.0008,
  "cache_size": 15,
  "is_loaded": true,
  "is_training": false,
  "model_path": "models/gemma-3n/extracted",
  "model_type": "tflite",
  "tflite_available": false
}
```

### 4. Consulta ao LLM ‚≠ê
**POST** `/api/llm/query`

**Endpoint principal para conversar com o Gemma 3N TFLite.**

**Payload:**
```json
{
  "question": "Como est√° o sistema de seguran√ßa?",
  "context": {},
  "include_system_context": true
}
```

**Par√¢metros:**
- `question` (string, obrigat√≥rio): A pergunta para o LLM
- `context` (object, opcional): Contexto adicional para a resposta
- `include_system_context` (boolean, opcional): Incluir contexto do sistema

**Resposta:**
```json
{
  "answer": "O sistema ATous Secure Network est√° funcionando normalmente com o modelo TFLite Gemma 3N.",
  "confidence": 0.8,
  "sources": ["llm", "system_metrics"],
  "metadata": {
    "question_type": "system_status",
    "response_length": 89,
    "has_context": true
  },
  "timestamp": "2025-08-17T22:15:00Z",
  "processing_time": 0.0008
}
```

### 5. WebSocket para Chat em Tempo Real
**GET** `/api/llm/ws`

Conex√£o WebSocket para chat em tempo real com o LLM.

**Mensagens de entrada:**
```json
{
  "type": "query",
  "question": "Como est√° o sistema?",
  "session_id": "user123"
}
```

**Mensagens de sa√≠da:**
```json
{
  "type": "response",
  "answer": "O sistema est√° funcionando perfeitamente!",
  "confidence": 0.8,
  "timestamp": "2025-08-17T22:15:00Z"
}
```

## üß™ Testando com Postman

### 1. Health Check
```
GET http://127.0.0.1:8000/health
```

### 2. Status do LLM
```
GET http://127.0.0.1:8000/api/llm/status
```

### 3. M√©tricas
```
GET http://127.0.0.1:8000/api/llm/metrics
```

### 4. Consulta ao LLM
```
POST http://127.0.0.1:8000/api/llm/query
Content-Type: application/json

{
  "question": "Como est√° o sistema de seguran√ßa?",
  "include_system_context": true
}
```

### 5. Exemplos de Perguntas

#### Sistema e Seguran√ßa
```json
{
  "question": "Qual √© o status atual do sistema de seguran√ßa?"
}
```

#### Usu√°rios e Amea√ßas
```json
{
  "question": "H√° alguma amea√ßa detectada no momento?",
  "include_system_context": true
}
```

#### Configura√ß√µes
```json
{
  "question": "Como posso otimizar as configura√ß√µes do ABISS?",
  "context": {"component": "abiss"}
}
```

#### Assist√™ncia Geral
```json
{
  "question": "Explique como funciona o sistema NNIS"
}
```

## üìä Respostas e Confian√ßa

### N√≠veis de Confian√ßa
- **0.9-1.0**: Resposta muito confi√°vel
- **0.8-0.9**: Resposta confi√°vel
- **0.7-0.8**: Resposta moderadamente confi√°vel
- **0.6-0.7**: Resposta com baixa confian√ßa
- **<0.6**: Resposta n√£o confi√°vel

### Fontes de Informa√ß√£o
- `llm`: Modelo Gemma 3N TFLite
- `abiss`: Sistema de seguran√ßa adaptativa
- `nnis`: Sistema neural imune
- `database`: Banco de dados de usu√°rios
- `system_metrics`: M√©tricas do sistema

## üîß Configura√ß√£o

### Vari√°veis de Ambiente
```bash
# Configura√ß√µes do LLM
LLM_MODEL_PATH=models/gemma-3n/extracted
LLM_MAX_LENGTH=2048
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9

# Configura√ß√µes do servidor
HOST=127.0.0.1
PORT=8000
```

### Modelo TFLite
O sistema usa automaticamente o modelo TFLite quando dispon√≠vel:
- **Caminho**: `models/gemma-3n/extracted`
- **Arquivo**: `gemma-3n-E2B-it-int4.task`
- **Tamanho**: ~3GB
- **Formato**: TensorFlow Lite

## üö® Tratamento de Erros

### C√≥digos de Status HTTP
- **200**: Sucesso
- **400**: Requisi√ß√£o inv√°lida
- **503**: Servi√ßo n√£o dispon√≠vel (modelo n√£o carregado)
- **500**: Erro interno do servidor

### Exemplos de Erro
```json
{
  "detail": "Modelo LLM n√£o est√° carregado. Aguarde o carregamento.",
  "status_code": 503
}
```

## üìà Monitoramento

### M√©tricas Importantes
- **Tempo de resposta**: < 0.001s (muito r√°pido)
- **Taxa de sucesso**: > 99%
- **Tamanho do cache**: Din√¢mico
- **Status do modelo**: Sempre verificar antes de consultar

### Logs
Os logs s√£o salvos em `logs/atous_network.log` com informa√ß√µes detalhadas sobre:
- Carregamento do modelo
- Consultas processadas
- Erros e exce√ß√µes
- Performance e m√©tricas

## üîç Debugging

### Verificar Status
```bash
# Ver logs em tempo real
tail -f logs/atous_network.log

# Testar endpoint
curl -X GET http://127.0.0.1:8000/api/llm/status

# Testar consulta
curl -X POST http://127.0.0.1:8000/api/llm/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Teste"}'
```

### Problemas Comuns
1. **Modelo n√£o carregado**: Verificar se o arquivo TFLite existe
2. **Erro de mem√≥ria**: Verificar recursos dispon√≠veis
3. **Timeout**: Aumentar timeout nas requisi√ß√µes
4. **Erro de conex√£o**: Verificar se o servidor est√° rodando

## üéØ Casos de Uso

### 1. Monitoramento de Seguran√ßa
```json
{
  "question": "H√° alguma atividade suspeita detectada?",
  "include_system_context": true
}
```

### 2. An√°lise de Usu√°rios
```json
{
  "question": "Quantos usu√°rios est√£o ativos e qual o padr√£o de acesso?",
  "context": {"analysis_type": "user_behavior"}
}
```

### 3. Otimiza√ß√£o do Sistema
```json
{
  "question": "Como posso melhorar a performance do sistema ABISS?",
  "include_system_context": true
}
```

### 4. Assist√™ncia T√©cnica
```json
{
  "question": "Explique como configurar um novo usu√°rio com permiss√µes de admin"
}
```

## üìö Recursos Adicionais

- **Documenta√ß√£o da API**: `/docs` (Swagger UI)
- **Especifica√ß√£o OpenAPI**: `/openapi.json`
- **Logs do sistema**: `logs/atous_network.log`
- **Configura√ß√µes**: `atous_sec_network/config/`

---

**üéâ A API LLM est√° pronta para uso! Teste com Postman e aproveite o poder do Gemma 3N TFLite!**
