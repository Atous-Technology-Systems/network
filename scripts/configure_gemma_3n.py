#!/usr/bin/env python3
"""
Script para configurar o Gemma 3N correto na aplica√ß√£o
"""

import json
import requests
from pathlib import Path

def verify_gemma_3n_model():
    """Verifica se o modelo Gemma 3N existe e est√° acess√≠vel"""
    model_name = "google/gemma-3n-E4B"
    
    print(f"üîç Verificando modelo: {model_name}")
    
    try:
        url = f"https://huggingface.co/api/models/{model_name}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            model_info = response.json()
            print(f"‚úÖ Modelo encontrado!")
            print(f"   Downloads: {model_info.get('downloads', 'N/A')}")
            print(f"   Likes: {model_info.get('likes', 'N/A')}")
            print(f"   √öltima atualiza√ß√£o: {model_info.get('lastModified', 'N/A')}")
            return True
        else:
            print(f"‚ùå Modelo n√£o encontrado (HTTP {response.status_code})")
            return False
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao verificar modelo: {e}")
        return False

def create_gemma_3n_config():
    """Cria configura√ß√£o otimizada para o Gemma 3N"""
    model_name = "google/gemma-3n-E4B"
    
    config = {
        "model_name": model_name,
        "model_params": {
            "torch_dtype": "float16",
            "device_map": "auto",
            "low_cpu_mem_usage": True,
            "trust_remote_code": True,
            "use_cache": True,
            "attn_implementation": "eager"  # Mais est√°vel para Gemma
        },
        "pipeline_params": {
            "max_length": 512,
            "max_new_tokens": 256,
            "temperature": 0.7,
            "do_sample": True,
            "top_p": 0.9,
            "top_k": 50,
            "repetition_penalty": 1.1,
            "pad_token_id": 0,
            "eos_token_id": 1
        },
        "memory_size": 1000,
        "threat_threshold": 0.7,
        "simulation_mode": False,
        "enable_monitoring": True,
        "learning_rate": 0.01
    }
    
    return config

def update_application_files():
    """Atualiza arquivos da aplica√ß√£o com Gemma 3N"""
    model_name = "google/gemma-3n-E4B"
    config = create_gemma_3n_config()
    
    # 1. Salvar configura√ß√£o JSON
    with open("gemma_config.json", "w") as f:
        json.dump(config, f, indent=2)
    print(f"‚úÖ Configura√ß√£o salva em: gemma_config.json")
    
    # 2. Atualizar __main__.py
    main_file = Path("atous_sec_network/__main__.py")
    if main_file.exists():
        with open(main_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Substituir configura√ß√£o ABISS
        old_abiss = 'abiss_config = {'
        new_abiss = f'''abiss_config = {{
            "model_name": "{model_name}",
            "model_params": {config["model_params"]},
            "pipeline_params": {config["pipeline_params"]},
            "memory_size": {config["memory_size"]},
            "threat_threshold": {config["threat_threshold"]},
            "simulation_mode": {str(config["simulation_mode"]).lower()},
            "enable_monitoring": {str(config["enable_monitoring"]).lower()},
            "learning_rate": {config["learning_rate"]}
        }}'''
        
        # Encontrar e substituir a configura√ß√£o ABISS
        import re
        abiss_pattern = r'abiss_config = \{[^}]*\}'
        content = re.sub(abiss_pattern, new_abiss.replace('{', '{{').replace('}', '}}'), content, flags=re.DOTALL)
        
        # Substituir configura√ß√£o NNIS
        nnis_pattern = r'nnis_config = \{[^}]*\}'
        new_nnis = f'''nnis_config = {{
            "model_name": "{model_name}",
            "model_params": {config["model_params"]},
            "simulation_mode": {str(config["simulation_mode"]).lower()},
            "memory_size": {config["memory_size"]},
            "immune_cell_count": 50,
            "memory_cell_count": 100,
            "threat_threshold": 0.8
        }}'''
        
        content = re.sub(nnis_pattern, new_nnis.replace('{', '{{').replace('}', '}}'), content, flags=re.DOTALL)
        
        with open(main_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"‚úÖ Arquivo {main_file} atualizado")
    
    # 3. Criar arquivo de configura√ß√£o Python
    config_dir = Path("atous_sec_network/config")
    config_dir.mkdir(exist_ok=True)
    
    config_file = config_dir / "gemma_3n_config.py"
    config_content = f'''"""
Configura√ß√£o Gemma 3N para ATous Secure Network
Modelo: {model_name}
"""

GEMMA_3N_CONFIG = {{
    "model_name": "{model_name}",
    "model_params": {config["model_params"]},
    "pipeline_params": {config["pipeline_params"]},
    "memory_size": {config["memory_size"]},
    "threat_threshold": {config["threat_threshold"]},
    "simulation_mode": {config["simulation_mode"]},
    "enable_monitoring": {config["enable_monitoring"]},
    "learning_rate": {config["learning_rate"]}
}}

# Configura√ß√µes espec√≠ficas para ABISS
ABISS_CONFIG = GEMMA_3N_CONFIG.copy()

# Configura√ß√µes espec√≠ficas para NNIS
NNIS_CONFIG = GEMMA_3N_CONFIG.copy()
NNIS_CONFIG.update({{
    "immune_cell_count": 50,
    "memory_cell_count": 100,
    "threat_threshold": 0.8
}})
'''
    
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print(f"‚úÖ Configura√ß√£o Python salva em: {config_file}")

def setup_huggingface_auth():
    """Configura autentica√ß√£o para acessar o Gemma 3N"""
    print("\nüîê Configurando autentica√ß√£o Hugging Face...")
    print("O modelo Gemma 3N pode requerer autentica√ß√£o.")
    
    try:
        import huggingface_hub
        
        # Verificar se j√° est√° logado
        try:
            token = huggingface_hub.get_token()
            if token:
                print("‚úÖ J√° autenticado no Hugging Face")
                return True
        except:
            pass
        
        print("\nüìã Para acessar o Gemma 3N:")
        print("1. Visite: https://huggingface.co/google/gemma-3n-E4B")
        print("2. Aceite os termos de uso do modelo")
        print("3. Execute: huggingface-cli login")
        print("4. Cole seu token de acesso")
        
        choice = input("\nDeseja fazer login agora? (y/n): ").lower().strip()
        
        if choice in ['y', 'yes', 'sim']:
            try:
                # Usar m√©todo Python em vez de CLI
                from huggingface_hub import login
                print("\nüåê Abrindo login do Hugging Face...")
                login()
                print("‚úÖ Login realizado com sucesso!")
                return True
            except Exception as e:
                print(f"‚ùå Erro no login: {e}")
                print("   Tente manualmente: python -c \"from huggingface_hub import login; login()\"")
                return True
        else:
            print("‚ö†Ô∏è  Login pulado. Voc√™ pode fazer depois com: huggingface-cli login")
            return True
            
    except ImportError:
        print("‚ö†Ô∏è  huggingface_hub n√£o instalado")
        print("   Instale com: pip install huggingface_hub")
        return False

def main():
    """Fun√ß√£o principal"""
    print("üöÄ Configurador Gemma 3N - ATous Secure Network")
    print("=" * 60)
    
    # Verificar se o modelo existe
    if not verify_gemma_3n_model():
        print("‚ùå N√£o foi poss√≠vel verificar o modelo Gemma 3N")
        return 1
    
    # Configurar autentica√ß√£o
    setup_huggingface_auth()
    
    # Atualizar arquivos da aplica√ß√£o
    print("\nüîß Atualizando configura√ß√µes da aplica√ß√£o...")
    update_application_files()
    
    print("\n‚úÖ Configura√ß√£o do Gemma 3N conclu√≠da!")
    print("\nüéØ Pr√≥ximos passos:")
    print("1. Se necess√°rio, fa√ßa login: huggingface-cli login")
    print("2. Teste a configura√ß√£o: python start_app.py --full")
    print("3. Verifique os logs para confirmar carregamento")
    print("4. Execute testes: python test_gemma_integration.py")
    
    print(f"\nüìä Informa√ß√µes do modelo:")
    print(f"   Nome: google/gemma-3n-E4B")
    print(f"   Tipo: Gemma 3N (Nova gera√ß√£o)")
    print(f"   URL: https://huggingface.co/google/gemma-3n-E4B")
    print(f"   Tamanho estimado: ~4-8GB")
    
    return 0

if __name__ == "__main__":
    exit(main())